{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"homework3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP3lJhMGUdLbDKaQLNYL1aP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"URkMmmUvq6RH"},"source":["# Dataset\n","In this homework, we will continue the *New York City Airbnb Open Data*. You can take it from Kaggle or download from here if you don't want to sign up to Kaggle.\n","\n","We'll keep working with the `price` variable, and we'll transform it to a classification task."]},{"cell_type":"code","metadata":{"id":"5PH-qS9cqr_-","executionInfo":{"status":"ok","timestamp":1632245185027,"user_tz":-180,"elapsed":196,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}}},"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.metrics import mean_squared_error, mutual_info_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction import DictVectorizer\n","from sklearn.linear_model import LogisticRegression, Ridge"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411},"id":"MLC0VZACq5h1","executionInfo":{"status":"ok","timestamp":1632244101983,"user_tz":-180,"elapsed":819,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}},"outputId":"f9935e23-db35-483d-adbf-577ab39adc6f"},"source":["data = pd.read_csv('https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv')\n","data.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>name</th>\n","      <th>host_id</th>\n","      <th>host_name</th>\n","      <th>neighbourhood_group</th>\n","      <th>neighbourhood</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>room_type</th>\n","      <th>price</th>\n","      <th>minimum_nights</th>\n","      <th>number_of_reviews</th>\n","      <th>last_review</th>\n","      <th>reviews_per_month</th>\n","      <th>calculated_host_listings_count</th>\n","      <th>availability_365</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2539</td>\n","      <td>Clean &amp; quiet apt home by the park</td>\n","      <td>2787</td>\n","      <td>John</td>\n","      <td>Brooklyn</td>\n","      <td>Kensington</td>\n","      <td>40.64749</td>\n","      <td>-73.97237</td>\n","      <td>Private room</td>\n","      <td>149</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>2018-10-19</td>\n","      <td>0.21</td>\n","      <td>6</td>\n","      <td>365</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2595</td>\n","      <td>Skylit Midtown Castle</td>\n","      <td>2845</td>\n","      <td>Jennifer</td>\n","      <td>Manhattan</td>\n","      <td>Midtown</td>\n","      <td>40.75362</td>\n","      <td>-73.98377</td>\n","      <td>Entire home/apt</td>\n","      <td>225</td>\n","      <td>1</td>\n","      <td>45</td>\n","      <td>2019-05-21</td>\n","      <td>0.38</td>\n","      <td>2</td>\n","      <td>355</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3647</td>\n","      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n","      <td>4632</td>\n","      <td>Elisabeth</td>\n","      <td>Manhattan</td>\n","      <td>Harlem</td>\n","      <td>40.80902</td>\n","      <td>-73.94190</td>\n","      <td>Private room</td>\n","      <td>150</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>365</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3831</td>\n","      <td>Cozy Entire Floor of Brownstone</td>\n","      <td>4869</td>\n","      <td>LisaRoxanne</td>\n","      <td>Brooklyn</td>\n","      <td>Clinton Hill</td>\n","      <td>40.68514</td>\n","      <td>-73.95976</td>\n","      <td>Entire home/apt</td>\n","      <td>89</td>\n","      <td>1</td>\n","      <td>270</td>\n","      <td>2019-07-05</td>\n","      <td>4.64</td>\n","      <td>1</td>\n","      <td>194</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5022</td>\n","      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n","      <td>7192</td>\n","      <td>Laura</td>\n","      <td>Manhattan</td>\n","      <td>East Harlem</td>\n","      <td>40.79851</td>\n","      <td>-73.94399</td>\n","      <td>Entire home/apt</td>\n","      <td>80</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>2018-11-19</td>\n","      <td>0.10</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     id  ... availability_365\n","0  2539  ...              365\n","1  2595  ...              355\n","2  3647  ...              365\n","3  3831  ...              194\n","4  5022  ...                0\n","\n","[5 rows x 16 columns]"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"4252XTaarslP"},"source":["# Features\n","For the rest of the homework, you'll need to use the features from the previous homework with additional two `neighbourhood_group` and `room_type`. So the whole feature set will be set as follows:\n","\n","* `neighbourhood_group`,\n","* `room_type`,\n","* `latitude`,\n","* `longitude`,\n","* `price`,\n","* `minimum_nights`,\n","* `number_of_reviews`,\n","* `reviews_per_month`,\n","* `calculated_host_listings_count`,\n","* `availability_365`\n","\n","Select only them and fill in the missing values with 0."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"F6gD1wxBrtbR","executionInfo":{"status":"ok","timestamp":1632244107934,"user_tz":-180,"elapsed":202,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}},"outputId":"1c77c9f8-5eb4-423b-d585-7bcead3d0b0c"},"source":["features = ['neighbourhood_group',\n","            'room_type',\n","            'latitude',\n","            'longitude',\n","            'minimum_nights',\n","            'number_of_reviews',\n","            'reviews_per_month',\n","            'calculated_host_listings_count',\n","            'availability_365',\n","            'price']\n","\n","# select features\n","data = data.loc[:, features].fillna(0)\n","\n","# string data normalization\n","categorical_columns = list(data.dtypes[data.dtypes == 'object'].index)\n","for c in categorical_columns:\n","    data[c] = data[c].str.lower().str.replace(' |/', '_')\n","\n","data.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>neighbourhood_group</th>\n","      <th>room_type</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>minimum_nights</th>\n","      <th>number_of_reviews</th>\n","      <th>reviews_per_month</th>\n","      <th>calculated_host_listings_count</th>\n","      <th>availability_365</th>\n","      <th>price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>brooklyn</td>\n","      <td>private_room</td>\n","      <td>40.64749</td>\n","      <td>-73.97237</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>0.21</td>\n","      <td>6</td>\n","      <td>365</td>\n","      <td>149</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>manhattan</td>\n","      <td>entire_home_apt</td>\n","      <td>40.75362</td>\n","      <td>-73.98377</td>\n","      <td>1</td>\n","      <td>45</td>\n","      <td>0.38</td>\n","      <td>2</td>\n","      <td>355</td>\n","      <td>225</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>manhattan</td>\n","      <td>private_room</td>\n","      <td>40.80902</td>\n","      <td>-73.94190</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>365</td>\n","      <td>150</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>brooklyn</td>\n","      <td>entire_home_apt</td>\n","      <td>40.68514</td>\n","      <td>-73.95976</td>\n","      <td>1</td>\n","      <td>270</td>\n","      <td>4.64</td>\n","      <td>1</td>\n","      <td>194</td>\n","      <td>89</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>manhattan</td>\n","      <td>entire_home_apt</td>\n","      <td>40.79851</td>\n","      <td>-73.94399</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>0.10</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>80</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  neighbourhood_group        room_type  ...  availability_365  price\n","0            brooklyn     private_room  ...               365    149\n","1           manhattan  entire_home_apt  ...               355    225\n","2           manhattan     private_room  ...               365    150\n","3            brooklyn  entire_home_apt  ...               194     89\n","4           manhattan  entire_home_apt  ...                 0     80\n","\n","[5 rows x 10 columns]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjjixtj-ueXp","executionInfo":{"status":"ok","timestamp":1632244112890,"user_tz":-180,"elapsed":269,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}},"outputId":"d0b0ff76-46cd-43dc-deb9-55a068cf9269"},"source":["data.info()"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 48895 entries, 0 to 48894\n","Data columns (total 10 columns):\n"," #   Column                          Non-Null Count  Dtype  \n","---  ------                          --------------  -----  \n"," 0   neighbourhood_group             48895 non-null  object \n"," 1   room_type                       48895 non-null  object \n"," 2   latitude                        48895 non-null  float64\n"," 3   longitude                       48895 non-null  float64\n"," 4   minimum_nights                  48895 non-null  int64  \n"," 5   number_of_reviews               48895 non-null  int64  \n"," 6   reviews_per_month               48895 non-null  float64\n"," 7   calculated_host_listings_count  48895 non-null  int64  \n"," 8   availability_365                48895 non-null  int64  \n"," 9   price                           48895 non-null  int64  \n","dtypes: float64(3), int64(5), object(2)\n","memory usage: 3.7+ MB\n"]}]},{"cell_type":"markdown","metadata":{"id":"I9HMNV6ksVNj"},"source":["# Question 1\n","What is the most frequent observation (mode) for the column `neighbourhood_group`?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"OZRLXneAsLMe","executionInfo":{"status":"ok","timestamp":1632244115323,"user_tz":-180,"elapsed":206,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}},"outputId":"45bb447c-6951-4215-cad7-2e76edbd6c01"},"source":["data['neighbourhood_group'].mode()[0]"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'manhattan'"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"VIqX56-Ju0ov","executionInfo":{"status":"ok","timestamp":1632244117013,"user_tz":-180,"elapsed":12,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}},"outputId":"71e780f5-f1dd-4866-bef9-54d168719313"},"source":["data['neighbourhood_group'].value_counts().index[0]"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'manhattan'"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"zYjtQ_kRvLe0"},"source":["# Split the data\n","Split your data in train/val/test sets, with 60%/20%/20% distribution.\n","Use `Scikit-Learn` for that (the `train_test_split` function) and set the `seed` to 42.\n","Make sure that the target value (`price`) is not in your dataframe."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RcJR739Ou8_j","executionInfo":{"status":"ok","timestamp":1632244121326,"user_tz":-180,"elapsed":202,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}},"outputId":"9b824116-9a57-46eb-f5d2-bcf5c874dd3a"},"source":["full_train, test = train_test_split(data, test_size=0.2, random_state=42)\n","train, val = train_test_split(full_train, test_size=0.25, random_state=42)\n","\n","len(train), len(val), len(test)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(29337, 9779, 9779)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"y-_MMVhx1NuS","executionInfo":{"status":"ok","timestamp":1632244123470,"user_tz":-180,"elapsed":211,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}}},"source":["train = train.reset_index(drop=True)\n","val = val.reset_index(drop=True)\n","test = test.reset_index(drop=True)\n","\n","y_train = train.price.values\n","y_val = val.price.values\n","y_test = test.price.values\n","\n","del train['price']\n","del val['price']\n","del test['price']"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uFabqyjN1oFB"},"source":["# Question 2\n","* Create the correlation matrix for the numerical features of your train dataset.\n","    * In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset.\n","* What are the two features that have the biggest correlation in this dataset?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"id":"GcT18Y7t1dBP","executionInfo":{"status":"ok","timestamp":1632244127907,"user_tz":-180,"elapsed":203,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}},"outputId":"5f5ed4ad-f491-4b81-e08d-0efde4aa134a"},"source":["numeric = list(train.select_dtypes(include=['int', 'float']).columns)\n","train[numeric].corr()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>minimum_nights</th>\n","      <th>number_of_reviews</th>\n","      <th>reviews_per_month</th>\n","      <th>calculated_host_listings_count</th>\n","      <th>availability_365</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>latitude</th>\n","      <td>1.000000</td>\n","      <td>0.080301</td>\n","      <td>0.027441</td>\n","      <td>-0.006246</td>\n","      <td>-0.007159</td>\n","      <td>0.019375</td>\n","      <td>-0.005891</td>\n","    </tr>\n","    <tr>\n","      <th>longitude</th>\n","      <td>0.080301</td>\n","      <td>1.000000</td>\n","      <td>-0.060660</td>\n","      <td>0.055084</td>\n","      <td>0.134642</td>\n","      <td>-0.117041</td>\n","      <td>0.083666</td>\n","    </tr>\n","    <tr>\n","      <th>minimum_nights</th>\n","      <td>0.027441</td>\n","      <td>-0.060660</td>\n","      <td>1.000000</td>\n","      <td>-0.076020</td>\n","      <td>-0.120703</td>\n","      <td>0.118647</td>\n","      <td>0.138901</td>\n","    </tr>\n","    <tr>\n","      <th>number_of_reviews</th>\n","      <td>-0.006246</td>\n","      <td>0.055084</td>\n","      <td>-0.076020</td>\n","      <td>1.000000</td>\n","      <td>0.590374</td>\n","      <td>-0.073167</td>\n","      <td>0.174477</td>\n","    </tr>\n","    <tr>\n","      <th>reviews_per_month</th>\n","      <td>-0.007159</td>\n","      <td>0.134642</td>\n","      <td>-0.120703</td>\n","      <td>0.590374</td>\n","      <td>1.000000</td>\n","      <td>-0.048767</td>\n","      <td>0.165376</td>\n","    </tr>\n","    <tr>\n","      <th>calculated_host_listings_count</th>\n","      <td>0.019375</td>\n","      <td>-0.117041</td>\n","      <td>0.118647</td>\n","      <td>-0.073167</td>\n","      <td>-0.048767</td>\n","      <td>1.000000</td>\n","      <td>0.225913</td>\n","    </tr>\n","    <tr>\n","      <th>availability_365</th>\n","      <td>-0.005891</td>\n","      <td>0.083666</td>\n","      <td>0.138901</td>\n","      <td>0.174477</td>\n","      <td>0.165376</td>\n","      <td>0.225913</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                latitude  ...  availability_365\n","latitude                        1.000000  ...         -0.005891\n","longitude                       0.080301  ...          0.083666\n","minimum_nights                  0.027441  ...          0.138901\n","number_of_reviews              -0.006246  ...          0.174477\n","reviews_per_month              -0.007159  ...          0.165376\n","calculated_host_listings_count  0.019375  ...          0.225913\n","availability_365               -0.005891  ...          1.000000\n","\n","[7 rows x 7 columns]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vSW-_SMP2F1_","executionInfo":{"status":"ok","timestamp":1632244130733,"user_tz":-180,"elapsed":228,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}},"outputId":"f813a01d-ab86-4ada-ea85-d59461616cf3"},"source":["train[numeric].corr().abs().unstack().sort_values(ascending = False)[len(numeric):len(numeric)+1].index[0]"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('number_of_reviews', 'reviews_per_month')"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"heCHAJi94Bfb"},"source":["# Make price binary\n","We need to turn the `price` variable from numeric into binary.\n","Let's create a variable `above_average` which is 1 if the `price` is above (or equal to) 152."]},{"cell_type":"code","metadata":{"id":"6RdtY11F2_Pu","executionInfo":{"status":"ok","timestamp":1632244134300,"user_tz":-180,"elapsed":197,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}}},"source":["above_average = (y_train >= 152).astype(int)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w2NT0mUq4uNW"},"source":["# Question 3\n","* Calculate the mutual information score with the (binarized) `price` for the two categorical variables that we have. Use the training set only.\n","* Which of these two variables has bigger score?\n","* Round it to 2 decimal digits using `round(score, 2)`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bGvpeX1g4n6X","executionInfo":{"status":"ok","timestamp":1632244141578,"user_tz":-180,"elapsed":250,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}},"outputId":"b0a3a1cf-b0ac-47bd-b8fa-70ae540ad54c"},"source":["categoric = list(train.select_dtypes(include='object').columns)\n","for col in categoric:\n","    print(f'{col:<20} - {mutual_info_score(train[col], above_average):.2f}')"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["neighbourhood_group  - 0.05\n","room_type            - 0.14\n"]}]},{"cell_type":"markdown","metadata":{"id":"CICd-Wy66WNi"},"source":["# Question 4\n","* Now let's train a logistic regression\n","* Remember that we have two categorical variables in the data. Include them using one-hot encoding.\n","* Fit the model on the training dataset.\n","    * To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n","    * `model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42)`\n","* Calculate the accuracy on the validation dataset and rount it to 2 decimal digits."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KP0lZEAjUT8B","executionInfo":{"status":"ok","timestamp":1632244171093,"user_tz":-180,"elapsed":1885,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}},"outputId":"f9392d76-410a-4530-cf98-46603cd6c773"},"source":["above_average_test = (y_val >= 152).astype(int)\n","\n","def get_accuracy(features):\n","    # one-hot encoding datasets\n","    dv = DictVectorizer(sparse=False)\n","\n","    train_dict = train[features].to_dict(orient='records')\n","    val_dict = val[features].to_dict(orient='records')\n","\n","    X_train = dv.fit_transform(train_dict)\n","    X_val = dv.transform(val_dict)\n","\n","    # training logistic regression\n","    model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42)\n","    model.fit(X_train, above_average)\n","\n","    # get accuracy on validation dataset\n","    predictions = model.predict(X_val)\n","    accuracy = np.sum(predictions == above_average_test) / len(X_val)\n","    \n","    return accuracy\n","\n","original_accuracy = get_accuracy(categoric + numeric)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]}]},{"cell_type":"code","metadata":{"id":"I1F55O-x5I9W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632244173811,"user_tz":-180,"elapsed":198,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}},"outputId":"3e4f9010-d7b7-4f6f-9738-d5729966bbbd"},"source":["print(f'Accuracy on validation dataset: {original_accuracy:.2f}')"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on validation dataset: 0.79\n"]}]},{"cell_type":"markdown","metadata":{"id":"hnNiPgMd9tt8"},"source":["# Question 5\n","* We have 9 features: 7 numerical features and 2 categorical.\n","* Let's find the least useful one using the *feature elimination* technique.\n","* Train a model with all these features (using the same parameters as in Q4).\n","* Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n","* For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n","* Which of following feature has the smallest difference?\n","    * `neighbourhood_group`\n","    * `room_type`\n","    * `number_of_reviews`\n","    * `reviews_per_month`\n","\n","> **note**: the difference doesn't have to be positive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JQWSaQb68xbG","executionInfo":{"status":"ok","timestamp":1632245090494,"user_tz":-180,"elapsed":13426,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}},"outputId":"4c1f3377-d315-4f50-f77a-bb57da35a940"},"source":["features = categoric + numeric\n","differences = pd.Series(dtype='float64')\n","\n","for feature in features:\n","    features_copy = features.copy()\n","    features_copy.remove(feature)\n","    accuracy = get_accuracy(features_copy)\n","    difference = original_accuracy - accuracy\n","    differences[feature] = difference"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"]}]},{"cell_type":"code","metadata":{"id":"Y3oRlX0X-5pm","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1632245092281,"user_tz":-180,"elapsed":205,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}},"outputId":"5df883cc-06f9-4e82-f261-c57a102684b8"},"source":["differences.sort_values().index[0]"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'number_of_reviews'"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"4hD7adPgYHzz"},"source":["# Question 6\n","* For this question, we'll see how to use a linear regression model from `Scikit-Learn`\n","* We'll need to use the original column `price`. Apply the logarithmic transformation to this column.\n","* Fit the `Ridge` regression model on the training data.\n","* This model has a parameter `alpha`. Let's try the following values: `[0, 0.01, 0.1, 1, 10]`\n","* Which of these alphas leads to the best RMSE on the validation set? Round your RMSE scores to 3 decimal digits.\n","\n","If there are multiple options, select the smallest `alpha`."]},{"cell_type":"code","metadata":{"id":"_7lhcfPtB4tZ","executionInfo":{"status":"ok","timestamp":1632245839388,"user_tz":-180,"elapsed":1315,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}}},"source":["features = categoric + numeric\n","\n","dv = DictVectorizer(sparse=False)\n","\n","train_dict = train[features].to_dict(orient='records')\n","val_dict = val[features].to_dict(orient='records')\n","\n","X_train = dv.fit_transform(train_dict)\n","X_val = dv.transform(val_dict)\n","y_train_log = np.log1p(y_train)\n","\n","alphas = [0, 0.01, 0.1, 1, 10]\n","\n","scores = pd.Series(dtype='float64')\n","\n","for alpha in alphas:\n","    model = Ridge(alpha=alpha)\n","    model.fit(X_train, y_train_log)\n","    predictions = model.predict(X_val)\n","    score = mean_squared_error(y_val, np.expm1(predictions), squared=False)\n","    scores[str(alpha)] = score"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9_9f8CraaSHu","executionInfo":{"status":"ok","timestamp":1632245861463,"user_tz":-180,"elapsed":228,"user":{"displayName":"Valerii Chetvertakov","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03842835578695755256"}},"outputId":"46d422a5-c113-48b4-80d8-970ef08e6274"},"source":["scores.sort_values().index[0]"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'0.01'"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"W7oh4pJNdenu"},"source":["<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\"><a href=\"https://twitter.com/hashtag/DataTalksClub?src=hash&amp;ref_src=twsrc%5Etfw\">#DataTalksClub</a> <a href=\"https://twitter.com/hashtag/MLZoomcamp?src=hash&amp;ref_src=twsrc%5Etfw\">#MLZoomcamp</a> Week 3 homework is ready. Notebook is disfigured with Convergence warnings from LogisticRegression :(</p>&mdash; sha of smile (@trueRock_n_roll) <a href=\"https://twitter.com/trueRock_n_roll/status/1440371370026627081?ref_src=twsrc%5Etfw\">September 21, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"]}]}